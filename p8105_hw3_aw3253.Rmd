---
title: HOMEWORK 3
author: "aw3253"
output: github_document
---

Preparing to load and tidy data:
```{r, message=FALSE}
library(tidyverse)
```




## Problem 1
```{r}
library(p8105.datasets)
data("instacart")

instacart
```

This data set has 15 variables collected from 1,384,617 products ordered on instacart.Some key variables are the product name, and where this product is located like the aisle,aisle_id, and department name. We also get some important information about the user that describes days since the last order to see how often a user orders from instacart or if they are a first-time user. For example, while user_id #112108 placed their last order 9 days ago, user_id #167740 placed their last order 2 days ago. 


```{r aisles info}
      
uniq_aisles = distinct(instacart, aisle_id)

aisle_count <- instacart %>%
  group_by(aisle_id) %>%
  summarize(n = n()) %>%
  arrange(desc(aisle_id))
```

There are 134 aisles, and it seems that the aisle most ordered from is aisle
83, fresh vegetables.



```{r aisle plot}

which_aisles = 
  instacart %>%
  group_by(aisle_id) %>%
  summarize(n = n()) %>%
  filter(n > 100000)

which_aisles

  ggplot(which_aisles, aes(x = aisle_id)) + 
  geom_histogram()+
   ggtitle("Figure 3: Number of orders in Aisles 24 and 83")


```

Aisles are ordered from least to greatest on the histogram, and only 2 aisles, fresh fruits and fresh vegetables had over 10,000 orders. 

```{r}

pop_data =
  instacart%>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(n = n()) %>% 
  filter(n == max(n))

pop_data
```

Light brown sugar is ordered the most in baking ingredients (499 orders), Snack Sticks Chicken & Rice Recipe Dog Treats is he popular product in the dog care aisle (30 orders), and organic baby spinach is the most popular i the packed vegetable fruits aisle (9784 orders).


```{r}

sweets = 
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(avg_hour = mean(order_hour_of_day))
  
sweets_final=
  pivot_wider(
    sweets, 
    names_from = "product_name", 
    values_from = "avg_hour")

sweets_final

```

On average, orders for Pink Lady Apples and Coffee Ice Cream are made between the 11th to 14th hour of the day.


## Problem 2

Loading Data:
```{r}
library(tidyverse)
library(p8105.datasets)
data("brfss")

brfss_smart2010
```


Tidying Data:
```{r, message=FALSE}

brfss = brfss_smart2010 %>%
janitor::clean_names()

brfss

brfss_sub <- brfss %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = as.factor(response))
  fct_relevel(brfss_sub $response, 
      "Poor",
      "Fair",
      "Very Good",
      "Good",
      "Excellent")
      
brfss_sub 
```


### Questions:
```{r}
states_02=
brfss_sub %>% 
  filter(year == 2002) %>% 
  distinct(locationabbr, locationdesc) %>% 
   count(locationabbr) %>% 
  filter(n >= 7)

states_02



states_10=
brfss_sub %>% 
  filter(year == 2010) %>% 
  distinct(locationabbr, locationdesc) %>% 
   count(locationabbr) %>% 
  filter(n >= 7)

states_10
```

In 2002, the states observed at 7+ locations were CT, FL, MA, NC, PA, and NJ

In 2010, the states observed at 7+ locations were CO, PA, CA, FL, MA MD, NC, NE, NJ, NY, OH, SC, TX, WA.




Average data values:
```{r, message=FALSE}

excellent_only =
  brfss_sub %>% 
  filter(response == "Excellent") %>% 
  group_by(locationabbr, year) %>% 
  distinct(locationdesc) %>% 
  count(locationabbr) %>% 
  ggplot(aes(x = year, y = n)) 
    geom_line(aes(color = locationabbr)) 
  
values_only =
  brfss_sub %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr, locationdesc, data_value) %>% 
  distinct(locationdesc) 

new=
pivot_wider(
    values_only, 
    names_from = "locationdesc", 
    values_from = "data_value")
new$avg_value <- rowMeans(new[ , c(3,406)], na.rm=TRUE)

```



NY 2006 and 2010:
```{r}
avg_response_ny =
  brfss_sub %>%
  filter(locationabbr == 'NY') %>%
  filter(year %in% c(2006, 2010)) %>%
  group_by(year, locationabbr, response) %>%
  summarize(avg_response = mean(data_value)) %>%
  ggplot(aes(x = year, y= avg_response)) +
    geom_point() 

avg_response_ny 
 
```


## Problem 3'
```{r}
run_df = 
 read_csv("data/accel_data.csv") %>%
   janitor::clean_names()
```


```{r}

run_df$tot_activity <- rowSums(run_df[ , c(4,1443)], na.rm=TRUE)

total_table = 
  select(run_df, week, day, tot_activity)
  
```

The weekends tend to have far less activity than the week days. During week 5 activity was the lowest compared to previous weeks.

```{r}
ggplot(total_table, aes(x = day, y = tot_activity, color = day)) + 
  geom_point(alpha = .5) 
```

Wednesdays and Sundays have the lowest 24-hour activity time course.

